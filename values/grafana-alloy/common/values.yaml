# Grafana Alloy configuration for homelab
# Unified telemetry collector - simplified for homelab

# Alloy configuration
alloy:
  # Config file content (River format)
  configMap:
    content: |
      // Logging configuration
      logging {
        level  = "info"
        format = "logfmt"
      }

      // ============================================
      // DISCOVERY
      // ============================================

      // Kubernetes service discovery for pods
      discovery.kubernetes "pods" {
        role = "pod"
      }

      // Kubernetes service discovery for nodes
      discovery.kubernetes "nodes" {
        role = "node"
      }

      // ============================================
      // METRICS COLLECTION
      // ============================================

      // Prometheus scrape for annotated pods
      // Pods with prometheus.io/scrape: "true"
      discovery.relabel "pods_metrics" {
        targets = discovery.kubernetes.pods.targets

        // Only keep pods with prometheus.io/scrape annotation
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_scrape"]
          action        = "keep"
          regex         = "true"
        }

        // Use custom port if specified
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_port", "__meta_kubernetes_pod_ip"]
          action        = "replace"
          regex         = "(\\d+);(.*)"
          replacement   = "$2:$1"
          target_label  = "__address__"
        }

        // Use custom path if specified
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_path"]
          action        = "replace"
          target_label  = "__metrics_path__"
          regex         = "(.+)"
        }

        // Add pod labels
        rule {
          action = "labelmap"
          regex  = "__meta_kubernetes_pod_label_(.+)"
        }

        // Add namespace label
        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          action        = "replace"
          target_label  = "namespace"
        }

        // Add pod name label
        rule {
          source_labels = ["__meta_kubernetes_pod_name"]
          action        = "replace"
          target_label  = "pod"
        }

        // Add node name label
        rule {
          source_labels = ["__meta_kubernetes_pod_node_name"]
          action        = "replace"
          target_label  = "node"
        }
      }

      prometheus.scrape "pods" {
        targets    = discovery.relabel.pods_metrics.output
        forward_to = [prometheus.remote_write.mimir.receiver]

        scrape_interval = "30s"
        scrape_timeout  = "10s"
      }

      // Kubelet metrics
      discovery.relabel "kubelet" {
        targets = discovery.kubernetes.nodes.targets

        rule {
          source_labels = ["__meta_kubernetes_node_name"]
          action        = "replace"
          target_label  = "node"
        }

        rule {
          action       = "replace"
          target_label = "__address__"
          replacement  = "kubernetes.default.svc:443"
        }

        rule {
          source_labels = ["__meta_kubernetes_node_name"]
          action        = "replace"
          target_label  = "__metrics_path__"
          regex         = "(.+)"
          replacement   = "/api/v1/nodes/$1/proxy/metrics"
        }
      }

      prometheus.scrape "kubelet" {
        targets    = discovery.relabel.kubelet.output
        forward_to = [prometheus.remote_write.mimir.receiver]

        scheme           = "https"
        scrape_interval  = "30s"
        scrape_timeout   = "10s"

        bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"

        tls_config {
          ca_file              = "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
          insecure_skip_verify = true
        }
      }

      // cAdvisor metrics (from kubelet)
      discovery.relabel "cadvisor" {
        targets = discovery.kubernetes.nodes.targets

        rule {
          source_labels = ["__meta_kubernetes_node_name"]
          action        = "replace"
          target_label  = "node"
        }

        rule {
          action       = "replace"
          target_label = "__address__"
          replacement  = "kubernetes.default.svc:443"
        }

        rule {
          source_labels = ["__meta_kubernetes_node_name"]
          action        = "replace"
          target_label  = "__metrics_path__"
          regex         = "(.+)"
          replacement   = "/api/v1/nodes/$1/proxy/metrics/cadvisor"
        }
      }

      prometheus.scrape "cadvisor" {
        targets    = discovery.relabel.cadvisor.output
        forward_to = [prometheus.remote_write.mimir.receiver]

        scheme           = "https"
        scrape_interval  = "30s"
        scrape_timeout   = "10s"

        bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"

        tls_config {
          ca_file              = "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
          insecure_skip_verify = true
        }
      }

      // Remote write to Mimir
      prometheus.remote_write "mimir" {
        endpoint {
          url = "http://mimir-nginx.monitoring.svc:80/api/v1/push"
        }
      }

      // ============================================
      // LOGS COLLECTION
      // ============================================

      // Discover and collect logs from pods
      loki.source.kubernetes "pods" {
        targets    = discovery.kubernetes.pods.targets
        forward_to = [loki.process.pods.receiver]
      }

      // Process logs - add labels
      loki.process "pods" {
        forward_to = [loki.write.loki.receiver]

        stage.static_labels {
          values = {
            cluster = "homelab",
          }
        }
      }

      // Write logs to Loki
      loki.write "loki" {
        endpoint {
          url = "http://loki.monitoring.svc:3100/loki/api/v1/push"
        }
      }

      // ============================================
      // TRACES COLLECTION
      // ============================================

      // OTLP receiver for traces
      otelcol.receiver.otlp "default" {
        grpc {
          endpoint = "0.0.0.0:4317"
        }
        http {
          endpoint = "0.0.0.0:4318"
        }

        output {
          traces = [otelcol.exporter.otlp.tempo.input]
        }
      }

      // Export traces to Tempo
      otelcol.exporter.otlp "tempo" {
        client {
          endpoint = "tempo.monitoring.svc:4317"

          tls {
            insecure = true
          }
        }
      }

# Deployment as DaemonSet to collect logs from all nodes
controller:
  type: daemonset

# Resources
resources:
  requests:
    cpu: 50m
    memory: 128Mi
  limits:
    cpu: 500m
    memory: 512Mi

# Service account
serviceAccount:
  create: true

# RBAC
rbac:
  create: true

# Tolerations to run on all nodes
tolerations:
  - operator: Exists

# Service
service:
  enabled: true
  type: ClusterIP

# Security context
securityContext:
  privileged: true
  runAsUser: 0

# Pod annotations
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "12345"
  prometheus.io/path: "/metrics"

# Extra mounts for log collection
extraVolumes:
  - name: varlog
    hostPath:
      path: /var/log
  - name: varlibdockercontainers
    hostPath:
      path: /var/lib/docker/containers

extraVolumeMounts:
  - name: varlog
    mountPath: /var/log
    readOnly: true
  - name: varlibdockercontainers
    mountPath: /var/lib/docker/containers
    readOnly: true
